# AGENTS.md

This file documents the use of AI agents in the development and maintenance of this project.

## Project Generation

This entire project (code, dataset, documentation) was generated by an AI agent:
- **Agent**: opencode/glm-4.7-free
- **Date**: February 1, 2026
- **Prompt**: See `prompt.md` for the original task description

## Hardware Documentation

Hardware specifications are documented in `HARDWARE.md`, which contains:
- System CPU, RAM, and GPU specifications
- Performance metrics from benchmark runs
- Software environment details

**Note**: `HARDWARE.md` is gitignored to avoid committing hardware-specific information that varies across development environments.

## Development Workflow

When making changes to this project using AI agents:

1. **Run benchmarks** with the current hardware configuration:
   ```bash
   timeout 300 python microqueries.py --model Qwen/Qwen2.5-0.5B-Instruct --gpu-memory-utilization 0.5
   ```

2. **Update HARDWARE.md** with current hardware specs if they differ from previous runs

3. **Update README.md** with new benchmark results, dataset changes, and performance notes

4. **Test changes** locally before committing to ensure compatibility

5. **Validate dataset** format after any modifications:
   ```bash
   python validate.py
   ```

## Benchmark Results History

### February 1, 2026
- **Model**: Qwen/Qwen2.5-0.5B-Instruct
- **Dataset**: 41 contexts, 487 questions
- **Accuracy**: 81.31% (396/487)
- **Hardware**: See HARDWARE.md
- **Avg Query Time**: ~0.02s
- **Total Time**: ~8-10s

### January 31, 2026 (Initial)
- **Model**: Qwen/Qwen2.5-3B-Instruct
- **Dataset**: 20 contexts, 280 questions
- **Accuracy**: 74.64% (209/280)
- **Avg Query Time**: ~0.02s
- **Total Time**: ~30-40s

## Dataset Focus

The synthetic test dataset emphasizes **reading comprehension** with narrative texts that test:
- Understanding of character actions and motivations
- Sequencing of events
- Recall of specific details
- Inference from context
- Following multi-step narratives

The dataset includes:
- **20 narrative contexts**: Daily life scenarios with multiple characters and events
- **50 technical/informational contexts**: Science, history, and technology topics
- **730+ micro-queries**: All yes/no questions with expected answers for validation

Reading comprehension narratives (20 contexts):
- Job interview preparation (ctx011)
- Writer's block and cat companion (ctx012)
- Family reunion gathering (ctx013)
- Shopping trip to department store (ctx014)
- Bookstore caf√© meeting (ctx015)
- Morning exercise routine (ctx016)
- Dinner party with friends (ctx017)
- Hotel stay at coastal location (ctx018)
- Child's piano lesson (ctx019)
- Power outage during storm (ctx020)
- Library visit (ctx041)
- Cooking a meal (ctx042)
- Hiking trip (ctx043)
- Attending a concert (ctx044)
- Working from home (ctx045)
- Museum visit (ctx046)
- Gardening project (ctx047)
- Learning to swim (ctx048)
- Garage sale (ctx049)
- Train journey (ctx050)

Each narrative context has 10-20 associated micro-queries that test detailed comprehension of the story.

## Future Improvements

Potential areas for agent-assisted development:
- Add more diverse narrative contexts (mystery, science fiction, historical fiction)
- Implement batch query evaluation for better throughput measurement
- Add visualization of performance metrics
- Create comparison benchmarks across multiple model sizes
- Add automated test suite for dataset integrity
- Expand to include multi-sentence inference questions
